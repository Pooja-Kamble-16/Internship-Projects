{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                              WEB SCRAPING ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium.commom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e5a04085d556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStaleElementReferenceException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium.commom'"
     ]
    }
   ],
   "source": [
    "#Firstly lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.commom.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Designation Search Bar\n",
    "search_desig=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "#Sending required key text to the element found.\n",
    "search_desig.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Location Search bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "#sending required key text to the element found\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using XPath function\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have reached our required page having Designation as Data Analyst and Location as Bangalore. Now, extract all the tags as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets extract the tags for job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the tags having job_titles\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the text of the job title is inside the tags extracted above.\n",
    "\n",
    "#so we will run a loop to iterate over the tags extracted above and extract first 10 job titles text.\n",
    "job_titles=[]\n",
    "for i in title_tags[0:10]:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will extract all the tags where we have Location of the job.\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the tags for Job Location. We will extract the text of first 10 from these tags one by one by looping over these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_list=[]\n",
    "for i in location_tags[0:10]:\n",
    "    location_list.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have all the tags in which there are company names.\n",
    "Now, lets extract the text of first 10 from these tags one by one using loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list=[]\n",
    "for i in company_tags[0:10]:\n",
    "    company_list.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So lets extract all the tags having the experience required.\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting text from the tags one by one using loop.\n",
    "exp_list=[]\n",
    "for i in exp_tags[0:10]:\n",
    "    exp_list.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of all the attributes\n",
    "print(len(job_titles))\n",
    "print(len(location_list))\n",
    "print(len(company_list))\n",
    "print(len(exp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Company</th>\n",
       "      <th>Required Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Hiring Data Analysts For E commerce Platform |...   \n",
       "2                                       Data Analyst   \n",
       "3  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "4  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "5                     Data Analyst - Informatica MDM   \n",
       "6  Assistant Vice President - MIS & Reporting ( B...   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                           Locations  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                        Mumbai, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                             Company Required Experience  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                   Allegis Services India Pvt. Ltd.             0-5 Yrs  \n",
       "2                                  Applied Materials            7-10 Yrs  \n",
       "3   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd             2-4 Yrs  \n",
       "4                     Tata Consultancy Services Ltd.             4-9 Yrs  \n",
       "5                Shell India Markets Private Limited             6-9 Yrs  \n",
       "6  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...           12-18 Yrs  \n",
       "7                           Myntra Designs Pvt. Ltd.             3-6 Yrs  \n",
       "8                           Myntra Designs Pvt. Ltd.             3-6 Yrs  \n",
       "9                           Myntra Designs Pvt. Ltd.             4-9 Yrs  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally create a dataframe of the scraped data.\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Locations']=location_list\n",
    "jobs['Company']=company_list\n",
    "jobs['Required Experience']=exp_list\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url2=\"https://www.naukri.com/\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Designation  search bar\n",
    "search_desig=driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required key text to the element found.\n",
    "search_desig.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Location search bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required key text to the element found.\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using XPath function\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have reached our required page having Designation as Data Analyst and Location as Bangalore. Now, extract all the tags as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets extract the tags for job_titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the element tags for job titles\n",
    "job_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Analytics & AI Product Mgmt - Sr. Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist, Modeling',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - Credit risk',\n",
       " 'Big Data - Data Scientist',\n",
       " 'SDE Lead Data Scientist-L3']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job title is inside the tags extracted above.\n",
    "\n",
    "#so we will run a loop to iterate over the tags extracted above and extract first 10 job titles text.\n",
    "job_titles=[]\n",
    "for i in job_tags[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "job_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will extract all the tags where we have Location of the job.\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the tags for Job Location. We will extract the text of first 10 from these tags one by one by looping over these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru, Vadodara, Mumbai (All Areas)',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Indore, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list=[]\n",
    "for i in location_tags[0:10]:\n",
    "    location_list.append(i.text)\n",
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets extract all the tags having the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have all the tags in which there are company names.\n",
    "Now, lets extract the text of first 10 from these tags one by one using loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Vijaya Management Services',\n",
       " 'Nielsen',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Scienaptic Systems',\n",
       " 'Xoriant Solutions Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_list=[]\n",
    "for i in company_tags[0:10]:\n",
    "    company_list.append(i.text)\n",
    "company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching url for each job_title page using for loop over job_tags\n",
    "urls=[]\n",
    "for i in job_tags:\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-data-analyst-business-analyst-inflexion-analytix-private-limited-mumbai-hyderabad-secunderabad-pune-gurgaon-gurugram-chennai-bangalore-bengaluru-0-to-3-years-100521000368?src=jobsearchDesk&sid=16209849032539138&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-analytics-ai-product-mgmt-sr-data-scientist-glaxosmithkline-pharmaceuticals-limited-bangalore-bengaluru-10-to-12-years-290421901995?src=jobsearchDesk&sid=16209849032539138&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-vijaya-management-services-pune-chennai-bangalore-bengaluru-5-to-10-years-290421005579?src=jobsearchDesk&sid=16209849032539138&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-modeling-nielsen-kolkata-gurgaon-gurugram-bangalore-bengaluru-vadodara-baroda-mumbai-all-areas-3-to-7-years-280421003878?src=jobsearchDesk&sid=16209849032539138&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-garage-ibm-india-pvt-limited-noida-hyderabad-secunderabad-bangalore-bengaluru-5-to-8-years-040521900448?src=jobsearchDesk&sid=16209849032539138&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-noida-hyderabad-secunderabad-bangalore-bengaluru-4-to-9-years-300421904650?src=jobsearchDesk&sid=16209849032539138&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-noida-hyderabad-secunderabad-bangalore-bengaluru-5-to-8-years-030521900421?src=jobsearchDesk&sid=16209849032539138&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-credit-risk-scienaptic-systems-bangalore-bengaluru-5-to-10-years-030521500996?src=jobsearchDesk&sid=16209849032539138&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-big-data-data-scientist-xoriant-solutions-pvt-ltd-kochi-cochin-indore-hyderabad-secunderabad-pune-ahmedabad-bangalore-bengaluru-mumbai-all-areas-1-to-3-years-130521005018?src=jobsearchDesk&sid=16209849032539138&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-sde-lead-data-scientist-l3-huawei-technologies-india-pvt-ltd-bangalore-bengaluru-5-to-8-years-120521901434?src=jobsearchDesk&sid=16209849032539138&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-computational-design-lead-data-scientist-l3-huawei-technologies-india-pvt-ltd-bangalore-bengaluru-5-to-8-years-120521901329?src=jobsearchDesk&sid=16209849032539138&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-110521907352?src=jobsearchDesk&sid=16209849032539138&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-intel-technology-india-pvt-ltd-bangalore-bengaluru-6-to-10-years-070521500578?src=jobsearchDesk&sid=16209849032539138&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-chatbot-nlp-gojek-tech-bangalore-bengaluru-3-to-7-years-060521500524?src=jobsearchDesk&sid=16209849032539138&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-chatbot-nlp-go-jek-india-bangalore-bengaluru-5-to-10-years-050521500478?src=jobsearchDesk&sid=16209849032539138&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-lead-data-scientist-for-bangalore-location-societe-generale-global-solution-centre-pvt-ltd-bangalore-bengaluru-5-to-9-years-130521000901?src=jobsearchDesk&sid=16209849032539138&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-kinara-financial-private-limited-bangalore-bengaluru-5-to-10-years-100521500393?src=jobsearchDesk&sid=16209849032539138&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-kinara-capital-kinara-financial-private-limited-bangalore-bengaluru-5-to-10-years-060521500976?src=jobsearchDesk&sid=16209849032539138&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-applied-materials-india-private-limited-bangalore-bengaluru-2-to-4-years-070521901521?src=jobsearchDesk&sid=16209849032539138&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-senior-data-scientist-o9-solutions-management-india-private-limited-bangalore-bengaluru-2-to-7-years-010521000099?src=jobsearchDesk&sid=16209849032539138&xp=20&px=1']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetched urls\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening each job_title page using get() and then extracting the full job description\n",
    "ful_desc=[]\n",
    "for i in urls[0:10]:\n",
    "    driver.get(i)\n",
    "    #Here we used xpath using OR function as we have two differeent value for class attribute\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"dang-inner-html\" or @class=\"clearboth description\"]'):\n",
    "        ful_desc.append(j.text)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ful_desc)#checking the length of fetched description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Full Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analytics &amp; AI Product Mgmt - Sr. Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Given the increased focus on data and analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Vijaya Management Services</td>\n",
       "      <td>.\\nRoles and Responsibilities\\nAnalyze structu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>We wont say we can predict the future, but our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>As a Data Scientist in the IBM Garage team you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Introduction\\nAs a Data Scientist at IBM, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Introduction\\nAs a Data Scientist at IBM, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Responsibilities and duties Focus on developin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>Roles &amp; Responsibilities &amp; Key Skills:\\n\\nBig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Business &amp; Team overview:\\nFounded in 1987, Hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0   Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Analytics & AI Product Mgmt - Sr. Data Scientist   \n",
       "2                             Senior Data Scientist   \n",
       "3                   Senior Data Scientist, Modeling   \n",
       "4                       Data Scientist - IBM Garage   \n",
       "5                                    Data Scientist   \n",
       "6                                    Data Scientist   \n",
       "7               Senior Data Scientist - Credit risk   \n",
       "8                         Big Data - Data Scientist   \n",
       "9                        SDE Lead Data Scientist-L3   \n",
       "\n",
       "                                           Locations  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "3  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "4  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "5  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "6  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 Companies  \\\n",
       "0       Inflexion Analytix Private Limited   \n",
       "1  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "2               Vijaya Management Services   \n",
       "3                                  Nielsen   \n",
       "4                   IBM India Pvt. Limited   \n",
       "5                   IBM India Pvt. Limited   \n",
       "6                   IBM India Pvt. Limited   \n",
       "7                       Scienaptic Systems   \n",
       "8                Xoriant Solutions Pvt Ltd   \n",
       "9        Huawei Technologies India Pvt Ltd   \n",
       "\n",
       "                                Full Job Description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1  Given the increased focus on data and analytic...  \n",
       "2  .\\nRoles and Responsibilities\\nAnalyze structu...  \n",
       "3  We wont say we can predict the future, but our...  \n",
       "4  As a Data Scientist in the IBM Garage team you...  \n",
       "5  Introduction\\nAs a Data Scientist at IBM, you ...  \n",
       "6  Introduction\\nAs a Data Scientist at IBM, you ...  \n",
       "7  Responsibilities and duties Focus on developin...  \n",
       "8  Roles & Responsibilities & Key Skills:\\n\\nBig ...  \n",
       "9  Business & Team overview:\\nFounded in 1987, Hu...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally creating dataframe for the scraped data\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Locations']=location_list\n",
    "jobs['Companies']=company_list\n",
    "jobs['Full Job Description']=ful_desc\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage.You have to use the location and salary filter. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url2=\"https://www.naukri.com/\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for Designation  search bar\n",
    "search_desig=driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required key text to the element found.\n",
    "search_desig.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using XPath function\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element for check-box of location filter \"Delhi/NCR\"\n",
    "check_box=driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']//i\")\n",
    "#Checking the check-box\n",
    "check_box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element for check-box of salary filter \"3-6 lakhs\"\n",
    "check_sal=driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']//i\")\n",
    "#Checking the check-box\n",
    "check_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the element tags for job titles\n",
    "job_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - High growth VC backed Influencer Marketplace',\n",
       " 'Excellent opportunity For Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'Data Scientist - Noida',\n",
       " \"Data Scientist - Noida/ B'lore\",\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job title is inside the tags extracted above.\n",
    "\n",
    "#so we will run a loop to iterate over the tags extracted above and extract first 10 job titles text.\n",
    "job_titles=[]\n",
    "for i in job_tags[0:10]:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will extract all the tags where we have Location of the job.\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'New Delhi, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Noida',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we have all the tags for Job Location. \n",
    "#We will extract the text of first 10 from these tags one by one by looping over these tags.\n",
    "location_list=[]\n",
    "for i in location[0:10]:\n",
    "    location_list.append(i.text)\n",
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets extract all the tags having the company name\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Ravgins International Pvt. Ltd.',\n",
       " 'NEC CORPORATION INDIA PRIVATE LIMITED',\n",
       " 'Mobikwik',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'NEC CORPORATION INDIA PRIVATE LIMITED',\n",
       " 'Cloudstrats Technologies Private Limited']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With this, we have all the tags in which there are company names.\n",
    "#Now, lets extract the text of first 10 from these tags one by one using loop.\n",
    "company_list=[]\n",
    "for i in company[0:10]:\n",
    "    company_list.append(i.text)\n",
    "company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So lets extract all the tags having the experience required.\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-8 Yrs']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting text from the tags one by one using loop.\n",
    "exp_list=[]\n",
    "for i in exp[0:10]:\n",
    "    exp_list.append(i.text)\n",
    "exp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_titles\n",
    "jobs['Locations']=location_list\n",
    "jobs['Companies']=company_list\n",
    "jobs['Experience Required']=exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist - High growth VC backed Influen...   \n",
       "3           Excellent opportunity For Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "7                             Data Scientist - Noida   \n",
       "8                     Data Scientist - Noida/ B'lore   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                           Locations  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3                         Noida, Bangalore/Bengaluru   \n",
       "4           New Delhi, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                              Noida   \n",
       "8                         Noida, Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "\n",
       "                                           Companies Experience Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                             IBM India Pvt. Limited             4-9 Yrs  \n",
       "2                    Ravgins International Pvt. Ltd.             3-5 Yrs  \n",
       "3              NEC CORPORATION INDIA PRIVATE LIMITED             3-7 Yrs  \n",
       "4                                           Mobikwik             3-5 Yrs  \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "6  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "7     Optum Global Solutions (India) Private Limited             3-5 Yrs  \n",
       "8              NEC CORPORATION INDIA PRIVATE LIMITED             3-8 Yrs  \n",
       "9           Cloudstrats Technologies Private Limited             5-8 Yrs  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url2=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for company_name and No. of days ago when job was posted\n",
    "company_name=[]\n",
    "days=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the designation search bar\n",
    "desig=driver.find_element_by_id(\"sc.keyword\")\n",
    "\n",
    "#sending required text to the element found\n",
    "desig.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library for the backspace key\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the location search bar using for loop and clearing it using the BACK_SPACE key\n",
    "for i in range(5):\n",
    "\n",
    "    driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\").send_keys(Keys.BACK_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the element tag of the location search bar in a variable\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending required text to the location search bar\n",
    "search_field_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search button\n",
    "btn=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on the search button element found\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tags for all the company names by iterating for loop\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']//span\"):\n",
    "    company_name.append(i.text)       #Extracting the text from the company_name tags \n",
    "    \n",
    "#finding element tags for the number of days by iteraing for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\"):\n",
    "    days.append(i.text)       #Extracting the text from the No. of Days tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to fetch the urls\n",
    "urls=[]\n",
    "\n",
    "#finding element tags to extract the urls for each company page\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\"):\n",
    "    urls.append(i.get_attribute('href'))     #Extracting the text from the urls tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for rating\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop for the first 10 urls\n",
    "for j in urls[:10]:\n",
    "    \n",
    "    #Getting the url webpage\n",
    "    driver.get(j)\n",
    "\n",
    "    #Using the NoSuchElementException where rating tag not found\n",
    "    try:\n",
    "        #finding element tag for the rating of the company\n",
    "        d=driver.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "        \n",
    "        #Extracting the text of the ratings\n",
    "        rating.append(d.text.replace('\\n',' '))\n",
    "    except NoSuchElementException:\n",
    "        #For the pages where the rating element tag is not found, appending it with \"-\"\n",
    "        rating.append(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Company Name']=company_name[:10]\n",
    "jobs['Number of days when Job was posted']=days[:10]\n",
    "jobs['Rating']=rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of days when Job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apsidata Solutions</td>\n",
       "      <td>3d</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>1d</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.4 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>11d</td>\n",
       "      <td>3.6 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.1 ★</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company Name Number of days when Job was posted Rating\n",
       "0            Apsidata Solutions                                 3d      -\n",
       "1                Biz2Credit Inc                               30d+      -\n",
       "2        Data Trained Education                                 1d      -\n",
       "3  Salasar New Age Technologies                               30d+      -\n",
       "4                      Techlive                               30d+  5.0 ★\n",
       "5                         Adobe                                 6d  4.4 ★\n",
       "6                 NatWest Group                                24h  3.9 ★\n",
       "7                     dunnhumby                                24h  4.1 ★\n",
       "8                       CRMNEXT                                11d  3.6 ★\n",
       "9                      Ericsson                                13d  4.1 ★"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url2=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for Job Title field bar\n",
    "search_job=driver.find_element_by_id(\"KeywordSearch\")\n",
    "\n",
    "#Sending required key text to the element found.\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for Location field bar\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\")\n",
    "\n",
    "#clearing the location field\n",
    "search_loc.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required key text to the location field.\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the search button\n",
    "driver.find_element_by_id(\"HeroSearchButton\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creatng empty lists to store our data for the attributes\n",
    "company_name=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "avg_sal=[]\n",
    "sal_no=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data by running For Loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the element tags having company name \n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "    company_name.append(i.text)    #Extracting text from the obtained tags and appending it to the company_name list\n",
    "\n",
    "#Extracting all the element tags having average salary \n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong'):\n",
    "    avg_sal.append(i.text.replace('/n',' '))    #Extracting text from the obtained tags and appending it to the avg_sal list\n",
    "    \n",
    "#Extracting all the element tags having salary numbers \n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "    sal_no.append(i.text)    #Extracting text from the obtained tags and appending it to the sal_no list\n",
    "\n",
    "#Extracting all the element tags having minimum salary \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']//span[1]\"):\n",
    "    min_sal.append(i.text)   #Extracting text from the obtained tags and appending it to the min_sal list\n",
    "\n",
    "#Extracting all the element tags having maximum salary \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']//span[2]\"):\n",
    "    max_sal.append(i.text)   #Extracting text from the obtained tags and appending it to the max_sal list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#checking length of all the attributes\n",
    "print(len(company_name))\n",
    "print(len(avg_sal))\n",
    "print(len(sal_no))\n",
    "print(len(min_sal))\n",
    "print(len(max_sal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>16 salaries</td>\n",
       "      <td>₹ 6,11,228</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 14,13,288</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Number of Salaries Average Salary Min Salary  \\\n",
       "0  Tata Consultancy Services        16 salaries     ₹ 6,11,228      ₹343K   \n",
       "1                  Accenture        14 salaries    ₹ 11,46,533      ₹577K   \n",
       "2                        IBM        14 salaries     ₹ 8,97,795      ₹586K   \n",
       "3         Ericsson-Worldwide        14 salaries     ₹ 7,38,057      ₹355K   \n",
       "4                  Delhivery        14 salaries    ₹ 12,39,781      ₹450K   \n",
       "5         UnitedHealth Group        11 salaries    ₹ 13,36,142    ₹1,069K   \n",
       "6         Valiance Solutions         9 salaries     ₹ 8,15,192      ₹502K   \n",
       "7              ZS Associates         8 salaries    ₹ 11,35,221      ₹202K   \n",
       "8                EXL Service         8 salaries    ₹ 11,44,243      ₹575K   \n",
       "9     Optum Global Solutions         8 salaries    ₹ 14,13,288    ₹1,014K   \n",
       "\n",
       "  Max Salary  \n",
       "0    ₹1,095K  \n",
       "1    ₹2,213K  \n",
       "2    ₹2,730K  \n",
       "3    ₹1,613K  \n",
       "4   ₹11,622K  \n",
       "5    ₹1,520K  \n",
       "6    ₹1,465K  \n",
       "7    ₹1,809K  \n",
       "8    ₹1,520K  \n",
       "9    ₹2,149K  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GlassDoorjobs=pd.DataFrame({})\n",
    "GlassDoorjobs['Company']=company_name[:10]\n",
    "GlassDoorjobs['Number of Salaries']=sal_no[:10]\n",
    "GlassDoorjobs['Average Salary']=avg_sal[:10]\n",
    "GlassDoorjobs['Min Salary']=min_sal[:10]\n",
    "GlassDoorjobs['Max Salary']=max_sal[:10]\n",
    "GlassDoorjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#Giving wait time for the webpage to load\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search bar\n",
    "search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required text to the element tag found\n",
    "search.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the search button tag found\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for the data to be fetched\n",
    "brands_list=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "disc_per=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the data from the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tags for the brands using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "    brands_list.append(i.text)       #Extracting text from the tags and append it to brands_list list\n",
    "    \n",
    "#finding element tags for the product description using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    product_desc.append(i.text)      #Extracting text from the tags and append it to product_desc list\n",
    "    \n",
    "#finding element tags for the price using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "    price.append(i.text)             #Extracting text from the tags and append it to price list\n",
    "    \n",
    "#finding element tags for the discount percent using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "    disc_per.append(i.text)          #Extracting text from the tags and append it to disc_per list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of all the lists\n",
    "print(len(brands_list))\n",
    "print(len(product_desc))\n",
    "print(len(price))\n",
    "print(len(disc_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the next page button\n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the data from the next pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop to fetch data from 2 pages\n",
    "for i in (0,2):\n",
    "    \n",
    "    #finding element tags for the brands using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brands_list.append(j.text)        #Extracting text from the tags and append it to brands_list list\n",
    "        \n",
    "    #finding element tags for the product description using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        product_desc.append(j.text)       #Extracting text from the tags and append it to product_desc list\n",
    "        \n",
    "    #finding element tags for the price using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(j.text)              #Extracting text from the tags and append it to price list\n",
    "        \n",
    "    #finding element tags for the discount percent using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        disc_per.append(j.text)           #Extracting text from the tags and append it to disc_per list\n",
    "        \n",
    "    #Clicking on the next page button\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()\n",
    "    time.sleep(4)     #Giving wait time for the webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "#Checking length of all the lists\n",
    "print(len(brands_list))\n",
    "print(len(product_desc))\n",
    "print(len(price))\n",
    "print(len(disc_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses=pd.DataFrame({})\n",
    "glasses['Brand']=brands_list[:100]\n",
    "glasses['Description']=product_desc[:100]\n",
    "glasses['Price']=price[:100]\n",
    "glasses['Discount']=disc_per[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹281</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹674</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹733</td>\n",
       "      <td>18% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>Gradient Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,181</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (56)</td>\n",
       "      <td>₹698</td>\n",
       "      <td>12% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval Sunglasses (60)</td>\n",
       "      <td>₹764</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "      <td>₹899</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹630   \n",
       "1           GANSTA              UV Protection Aviator Sunglasses (57)    ₹281   \n",
       "2   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹499   \n",
       "3         Fastrack       UV Protection Aviator Sunglasses (Free Size)    ₹674   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹733   \n",
       "..             ...                                                ...     ...   \n",
       "95            IDEE                   Gradient Aviator Sunglasses (58)  ₹1,181   \n",
       "96        Fastrack          UV Protection Rectangular Sunglasses (56)    ₹698   \n",
       "97          AISLIN                 UV Protection Oval Sunglasses (60)    ₹764   \n",
       "98       ROYAL SON             Polarized Retro Square Sunglasses (58)    ₹899   \n",
       "99            hipe  UV Protection, Mirrored Round Sunglasses (Free...    ₹219   \n",
       "\n",
       "   Discount  \n",
       "0   21% off  \n",
       "1   85% off  \n",
       "2   77% off  \n",
       "3   25% off  \n",
       "4   18% off  \n",
       "..      ...  \n",
       "95  58% off  \n",
       "96  12% off  \n",
       "97  69% off  \n",
       "98  55% off  \n",
       "99  86% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "You have to scrape the attributes.\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url)\n",
    "time.sleep(5)     #Giving wait time for the webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to store the fetched data\n",
    "rating=[]\n",
    "review_sum=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking to go to All Reviews page\n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tags for Ratings data on 1st page\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "    rating.append(i.text)      #Extracting text from tags and storing it in respective Rating variable\n",
    "    \n",
    "#finding element tags for Review Summary data on 1st page\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "    review_sum.append(i.text)  #Extracting text from tags and storing it in respective Review Summary variable\n",
    "    \n",
    "#finding element tags for Full Review data on 1st page\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "    full_review.append(i.text) #Extracting text from tags and storing it in respective Full Review variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Next button\n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the for loop to fetch the data from multiple pages\n",
    "for i in range(0,10):\n",
    "    \n",
    "    #Running loop to find element tags for Rating\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq' or @class='_3LWZlK _1rdVr6 _1BLPMq']\"):\n",
    "        rating.append(j.text)      #Extracting text from rating tags \n",
    "        \n",
    "    #Running loop to find element tags for Review Summary\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        review_sum.append(j.text)  #Extracting text from review summary tags \n",
    "        \n",
    "    #Running loop to find element tags for Full Review\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        full_review.append(j.text) #Extracting text from full review tags \n",
    "        \n",
    "    #Clicking to move to next page\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()\n",
    "    \n",
    "    time.sleep(4)    #Giving wait time for the webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "110\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "#printing the length of each attribute\n",
    "print(len(rating))\n",
    "print(len(review_sum))\n",
    "print(len(full_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone=pd.DataFrame({})\n",
    "iphone['Rating']=rating[:100]\n",
    "iphone['Review Sumary']=review_sum[:100]\n",
    "iphone['Full Review']=full_review[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Sumary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Just an awesome phone...upgraded from 6s to 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>As usual a great product from Apple. but the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Sumary  \\\n",
       "0       5          Brilliant   \n",
       "1       5   Perfect product!   \n",
       "2       5      Great product   \n",
       "3       5  Worth every penny   \n",
       "4       4        Good choice   \n",
       "..    ...                ...   \n",
       "95      5          Excellent   \n",
       "96      5          Fabulous!   \n",
       "97      5          Wonderful   \n",
       "98      5          Fabulous!   \n",
       "99      4    Value-for-money   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  A perfect phone and a good battery super camer...  \n",
       "96  Everything is perfect pictures come out so cle...  \n",
       "97  Nice value for money good and best price I pho...  \n",
       "98  Just an awesome phone...upgraded from 6s to 11...  \n",
       "99  As usual a great product from Apple. but the l...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#Giving wait time for the webpage to load\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search bar\n",
    "search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required text to the element tag found\n",
    "search.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search button\n",
    "btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the search button tag found\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to store the fetched data\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "disc_per=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the data from the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tags for the brands using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "    brand.append(i.text)               #Extracting text from the tags and append it to brand list\n",
    "    \n",
    "#finding element tags for the product description using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\"):\n",
    "    product_desc.append(i.text)        #Extracting text from the tags and append it to product_desc list\n",
    "    \n",
    "#finding element tags for the price using for loop\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "    price.append(i.text)               #Extracting text from the tags and append it to price list\n",
    "    \n",
    "#finding element tags for the urls using for loop to fetch the discount percentage\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\"):\n",
    "    urls.append(i.get_attribute('href'))       #Extracting text from the tags and append it to ursl list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of each list\n",
    "print(len(brand))\n",
    "print(len(product_desc))\n",
    "print(len(price))\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing NoSuchElementException package\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop over urls list to open each page \n",
    "for j in urls:\n",
    "    \n",
    "    #Getting the webpage\n",
    "    driver.get(j)\n",
    "    \n",
    "    #Using the NoSuchElementException where discount percent tag is not found\n",
    "    try:\n",
    "        #finding element tag for the discount percent of the company\n",
    "        d=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        \n",
    "        #Extracting the text of the discount percent\n",
    "        disc_per.append(d.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        #For the pages where the discount percent element tag is not found, appending it with \"-\"\n",
    "        disc_per.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disc_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending required text to the search bar\n",
    "driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\").send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search button\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the next page button\n",
    "nextpg=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on next button\n",
    "nextpg.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop for the next two pages\n",
    "for j in range(0,2):\n",
    "    \n",
    "    #finding element tags for the brands using for loop\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(i.text)       #Extracting text from the tags and append it to brand list\n",
    "        \n",
    "    #finding element tags for the product description using for loop\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\"):\n",
    "        product_desc.append(i.text)        #Extracting text from the tags and append it to product_desc list\n",
    "        \n",
    "    #finding element tags for the price using for loop\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(i.text)       #Extracting text from the tags and append it to price list\n",
    "        \n",
    "    #finding element tags to extract url of each sneaker using for loop\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\"):\n",
    "        urls.append(i.get_attribute('href'))         #Extracting url from the attribute and append it to urls list\n",
    "        \n",
    "    #Cliking to move to the next page\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()\n",
    "    time.sleep(4)         #Giving wait time for the webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop over urls list to open each page \n",
    "for j in urls[40:]:\n",
    "    \n",
    "    #Getting the webpage\n",
    "    driver.get(j)\n",
    "    \n",
    "    #Using the NoSuchElementException where discount percent tag is not found\n",
    "    try:\n",
    "        #finding element tag for the discount percent of the company\n",
    "        d=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        \n",
    "        #Extracting the text of the discount percent\n",
    "        disc_per.append(d.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        #For the pages where the discount percent element tag is not found, appending it with \"-\"\n",
    "        disc_per.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "#Checking length before creating dataframe\n",
    "print(len(brand))\n",
    "print(len(product_desc))\n",
    "print(len(price))\n",
    "print(len(disc_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers=pd.DataFrame({})\n",
    "sneakers['Brand']=brand\n",
    "sneakers['Description']=product_desc\n",
    "sneakers['Price']=price\n",
    "sneakers['Discount %']=disc_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROADSTER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,919</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rising Wolf</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹485</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men (beige 06) Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Icon IDP Sneakers For Men</td>\n",
       "      <td>₹1,220</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Trenzo II IDP Sneakers For Men</td>\n",
       "      <td>₹1,349</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GRSHOE</td>\n",
       "      <td>SUP FANCY IMPORTED RUNNING SHOES FOR MEN. Snea...</td>\n",
       "      <td>₹365</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>LEVI'S</td>\n",
       "      <td>INDI WISH Sneaker For Men</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                        Description   Price  \\\n",
       "0        ROADSTER                                   Sneakers For Men  ₹1,919   \n",
       "1     Rising Wolf                                   Sneakers For Men    ₹485   \n",
       "2    Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men    ₹399   \n",
       "3            aadi                                   Sneakers For Men    ₹298   \n",
       "4    Robbie jones                                   Sneakers For Men    ₹474   \n",
       "..            ...                                                ...     ...   \n",
       "115     bluemaker         casual for men (beige 06) Sneakers For Men    ₹474   \n",
       "116          PUMA                          Icon IDP Sneakers For Men  ₹1,220   \n",
       "117          PUMA                     Trenzo II IDP Sneakers For Men  ₹1,349   \n",
       "118        GRSHOE  SUP FANCY IMPORTED RUNNING SHOES FOR MEN. Snea...    ₹365   \n",
       "119        LEVI'S                          INDI WISH Sneaker For Men  ₹1,999   \n",
       "\n",
       "    Discount %  \n",
       "0      31% off  \n",
       "1      75% off  \n",
       "2      60% off  \n",
       "3      70% off  \n",
       "4      52% off  \n",
       "..         ...  \n",
       "115    52% off  \n",
       "116    63% off  \n",
       "117    55% off  \n",
       "118    63% off  \n",
       "119    50% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store the require data\n",
    "brand=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding elemnt tag for the checkbox of color filter\n",
    "color_filter=driver.find_element_by_xpath(\"//label[@class='common-customCheckbox']//span\")\n",
    "\n",
    "#Clicking to check the checkbox\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tags for the price filter checkbox\n",
    "price_filter=driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we will run a loop to iterate over the tags extracted above and extracting text\n",
    "for i in price_filter:\n",
    "    \n",
    "    #Using if-else condition to match the text with the required text\n",
    "    if i.text[:21]=='Rs. 6649 to Rs. 13099':\n",
    "        i.click()       #Clicking the checkbox once the required price text is found\n",
    "        break           #Using break statement once its found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using for loop to run over 2 pages to extract the required data\n",
    "for i in range(0,2):\n",
    "    \n",
    "    #finding the elements tags for the brands using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        brand.append(j.text)           #Extracting text from the tags and appending it to brand list\n",
    "        \n",
    "    #finding the elements tags for the short_desc using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        short_desc.append(j.text)      #Extracting text from the tags and appending it to shoe description list\n",
    "        \n",
    "    #finding the elements tags for the url of each shoes using for loop\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='product-base']//a\"):\n",
    "        urls.append(j.get_attribute('href'))       #Extracting url from the attribute and append it to urls list\n",
    "        \n",
    "    #Clicking to move to the next page\n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']\").click()\n",
    "    time.sleep(4)         #Giving wait time for the webpage to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop over the urls list to fetch the price of each shoes\n",
    "for i in urls:\n",
    "    \n",
    "    #Getting the required webpage\n",
    "    driver.get(i)\n",
    "    \n",
    "    #finding the elements tags for the price using for loop\n",
    "    for j in driver.find_element_by_xpath(\"//span[@class='pdp-price']\"):\n",
    "        price.append(j.text)       #Extracting text from the tags and appending it to price list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes=pd.DataFrame({})\n",
    "shoes['Brand']=brand\n",
    "shoes['Description']=short_desc\n",
    "shoes['Price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>Rs. 8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 10846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women PEGASUS 37 Running Shoes</td>\n",
       "      <td>Rs. 7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Unisex Zig Kinetica II Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Heeled Boots</td>\n",
       "      <td>Rs. 11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Supernova Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                      Description      Price\n",
       "0              Nike      Men JORDAN DELTA Basketball  Rs. 12495\n",
       "1              Nike        Women REACT Running Shoes   Rs. 8396\n",
       "2   PUMA Motorsport    Unisex Mercedes Running Shoes   Rs. 7999\n",
       "3              Nike       Men React Infinity Running  Rs. 10846\n",
       "4              Nike   Women PEGASUS 37 Running Shoes   Rs. 7496\n",
       "..              ...                              ...        ...\n",
       "95           Reebok   Unisex Zig Kinetica II Running   Rs. 9999\n",
       "96        Florsheim  Men Solid Leather Formal Derbys   Rs. 6995\n",
       "97          Saint G             Leather Heeled Boots  Rs. 11800\n",
       "98           ADIDAS      Men Supernova Running Shoes   Rs. 7999\n",
       "99             FILA             Women Solid Sneakers   Rs. 6999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”. \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the required webpage\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "#Giving time for the webpage to load\n",
    "time.sleep(4)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search bar\n",
    "search=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "\n",
    "#Sending the required text\n",
    "search.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element tag for the search button\n",
    "btn=driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']/span/input\")\n",
    "\n",
    "#Clicking the button\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for the required data\n",
    "title=[]\n",
    "ratings=[]\n",
    "price=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the element tags for the checkbox texts\n",
    "icore=driver.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop over the obtained tags\n",
    "for i in icore:\n",
    "    \n",
    "        #Using if condition to find the text matching required filter\n",
    "        if i.text=='Intel Core i7':\n",
    "            \n",
    "            #Clicking the checkbox\n",
    "            i.click()\n",
    "            break     #Using the break statement once the condition is satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding elements tags for all the urls\n",
    "url_tag=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "#Using for loop to run over the first 5 obtained tags\n",
    "for i in url_tag[:5]:\n",
    "    \n",
    "    #Extracting the url using the href attribute\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Clear to go back to last page\n",
    "driver.find_element_by_xpath(\"//a[@class='a-link-normal s-navigation-item s-navigation-clear-link']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using for loop to find the element tags for the checkbox texts\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\"):\n",
    "    \n",
    "    #Using if condition to find the text matching required filter\n",
    "    if i.text=='Intel Core i9':\n",
    "        \n",
    "            #Clicking the checkbox\n",
    "            i.click()\n",
    "            break       #Using the break statement once the condition is satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding elements tags for all the urls\n",
    "url_tagi9=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "#Using for loop to run over the first 5 obtained tags\n",
    "for i in url_tagi9[:5]:\n",
    "    \n",
    "    #Extracting the url using the href attribute\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running for loop over the each url in urls list\n",
    "for i in urls:\n",
    "    \n",
    "    #Getting the webpage\n",
    "    driver.get(i)\n",
    "    \n",
    "    #finding element tag for the laptop title\n",
    "    d=driver.find_element_by_id(\"productTitle\") \n",
    "    #Extracting the text from obtained tag\n",
    "    title.append(d.text.replace(\"/n\",' '))\n",
    "    \n",
    "    #Using the NoSuchElementException where rating tag is not found\n",
    "    try:\n",
    "        #finding the element tag for the rating\n",
    "        r=driver.find_element_by_xpath(\"//a[@class='a-popover-trigger a-declarative']//i//span\")\n",
    "        #Extracting text from the tag obtained\n",
    "        ratings.append(r.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        #Appending '-' where the price tag is not found\n",
    "        ratings.append('-')\n",
    "       \n",
    "    #Using the NoSuchElementException where price tag is not found\n",
    "    try:\n",
    "        #finding the element tag for the price\n",
    "        p=driver.find_element_by_id(\"priceblock_ourprice\")\n",
    "        price.append(p.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        price.append('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have scraped all the required data from these tags. Lets create dataframe for this scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=pd.DataFrame({})\n",
    "laptop['Title']=title\n",
    "laptop['Ratings']=ratings\n",
    "laptop['Price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 47,050.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 83,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 85,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 86,926.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 2,99,325.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 2,62,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>-</td>\n",
       "      <td>₹ 2,66,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 2,48,790.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...</td>\n",
       "      <td></td>\n",
       "      <td>₹ 2,77,490.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings          Price\n",
       "0  Life Digital Laptop 15.6-inch (39.62 cms) (Int...            ₹ 47,050.00\n",
       "1  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...            ₹ 83,990.00\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...                      -\n",
       "3  Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...            ₹ 85,990.00\n",
       "4  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...            ₹ 86,926.00\n",
       "5  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...          ₹ 2,99,325.00\n",
       "6  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...          ₹ 2,62,990.00\n",
       "7  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...       -  ₹ 2,66,990.00\n",
       "8  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...          ₹ 2,48,790.00\n",
       "9  ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...          ₹ 2,77,490.00"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
