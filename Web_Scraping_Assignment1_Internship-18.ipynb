{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "print(page)\n",
    "#see page content\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the header tags:\n",
      "--------------------------------------------------\n",
      "h1 Main Page\n",
      "h2 From today's featured article\n",
      "h2 Did you know ...\n",
      "h2 In the news\n",
      "h2 On this day\n",
      "h2 From today's featured list\n",
      "h2 Today's featured picture\n",
      "h2 Other areas of Wikipedia\n",
      "h2 Wikipedia's sister projects\n",
      "h2 Wikipedia languages\n",
      "h2 Navigation menu\n",
      "h3 Personal tools\n",
      "h3 Namespaces\n",
      "h3 Variants\n",
      "h3 Views\n",
      "h3 More\n",
      "h3 Search\n",
      "h3 Navigation\n",
      "h3 Contribute\n",
      "h3 Tools\n",
      "h3 Print/export\n",
      "h3 In other projects\n",
      "h3 Languages\n"
     ]
    }
   ],
   "source": [
    "print(\"List of all the header tags:\\n\",'-'*50,sep='')\n",
    "#Using for loop scraping all the heading tags\n",
    "for headings in soup.find_all([\"h1\",\"h2\",\"h3\"]):\n",
    "    print(headings.name+\" \"+headings.text.strip()) #printing all the header tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists to scrape required data\n",
    "movie_names=[]\n",
    "imbd_ratings=[]\n",
    "release_year=[]\n",
    "\n",
    "#Top 100 Movie Names\n",
    "name = soup.find_all(\"h3\",class_=\"lister-item-header\") #Getting web elements for movie names\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_names.append(j.text) #Getting text of the names from web elements using nested for loop\n",
    "\n",
    "#IMBD Ratings\n",
    "ratings = soup.find_all(\"div\",class_=\"ipl-rating-star small\") #Getting web elements for IMBD ratings\n",
    "for i in ratings:\n",
    "    imbd_ratings.append(i.text.replace(\"\\n\",'')) #Getting text from the web elements\n",
    "    \n",
    "#Year Of Release\n",
    "year = soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\") #Getting web elements for year of release\n",
    "for i in year:\n",
    "    release_year.append(i.text) #Getting text for year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Checking the lengths for each list\n",
    "print(len(movie_names))\n",
    "print(len(imbd_ratings))\n",
    "print(len(release_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>IMDB Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Movie Title IMDB Ratings Year of Release\n",
       "0              The Shawshank Redemption          9.3          (1994)\n",
       "1                         The Godfather          9.2          (1972)\n",
       "2                The Godfather: Part II            9          (1974)\n",
       "3                       The Dark Knight            9          (2008)\n",
       "4                          12 Angry Men            9          (1957)\n",
       "..                                  ...          ...             ...\n",
       "95                   North by Northwest          8.3          (1959)\n",
       "96                   A Clockwork Orange          8.3          (1971)\n",
       "97                               Snatch          8.3          (2000)\n",
       "98  Le fabuleux destin d'Amélie Poulain          8.3          (2001)\n",
       "99                              The Kid          8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for IMBD's rated Top 100 Movies\n",
    "IMBD_top100Movies = pd.DataFrame({})\n",
    "IMBD_top100Movies[\"Movie Title\"] = movie_names\n",
    "IMBD_top100Movies[\"IMDB Ratings\"] = imbd_ratings\n",
    "IMBD_top100Movies[\"Year of Release\"] = release_year\n",
    "IMBD_top100Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists to store the scraped data\n",
    "m_name = []\n",
    "imbd_rate = []\n",
    "year_release = []\n",
    "\n",
    "#Top Indian Movie\n",
    "name = soup.find_all(\"h3\",class_=\"lister-item-header\") #Get movie name web elements\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        m_name.append(j.text) #Get text from movie name web elements\n",
    "        \n",
    "#IMBD Ratings\n",
    "ratings = soup.find_all(\"div\",class_=\"ipl-rating-star small\") #Get ratings web elements\n",
    "for i in ratings:\n",
    "    imbd_rate.append(i.text.replace(\"\\n\",\"\")) #Get text from ratings' web elements\n",
    "    \n",
    "#Year Of Release\n",
    "year = soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\") #Get Year of Release web elements\n",
    "for i in year:\n",
    "    year_release.append(i.text) #Get text from year of release web elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Checking the lengths for each list\n",
    "print(len(m_name))\n",
    "print(len(imbd_rate))\n",
    "print(len(year_release))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>IMBD Ratings</th>\n",
       "      <th>Year Of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>7.7</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Movie Title IMBD Ratings Year Of Release\n",
       "0          Rang De Basanti          8.1          (2006)\n",
       "1                 3 Idiots          8.4          (2009)\n",
       "2         Taare Zameen Par          8.4          (2007)\n",
       "3           Dil Chahta Hai          8.1          (2001)\n",
       "4   Swades: We, the People          8.2          (2004)\n",
       "..                     ...          ...             ...\n",
       "95             Wake Up Sid          7.6          (2009)\n",
       "96                Rangeela          7.5          (1995)\n",
       "97     Shatranj Ke Khilari          7.7          (1977)\n",
       "98      Pyaar Ka Punchnama          7.6          (2011)\n",
       "99           Ek Hasina Thi          7.5          (2004)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for IMBD's Top rated 100 Indian Movies\n",
    "IMBD_top100_IndianMovies = pd.DataFrame({})\n",
    "IMBD_top100_IndianMovies[\"Movie Title\"] = m_name\n",
    "IMBD_top100_IndianMovies[\"IMBD Ratings\"] = imbd_rate\n",
    "IMBD_top100_IndianMovies[\"Year Of Release\"] = year_release\n",
    "IMBD_top100_IndianMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://bookpage.com/reviews/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "urls=[] #Empty list\n",
    "url_tags=soup.find_all(\"h4\",class_=\"italic\") #Extracting web elements for Book URLs\n",
    "for i in url_tags:\n",
    "    for j in i.find_all(\"a\",href=True):\n",
    "        if j.text:\n",
    "            urls.append(j['href']) #Get URL from the web elements and store in list\n",
    "    \n",
    "#Empty lists for the required data\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "genre=[]\n",
    "book_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/reviews/26459-leslie-jordan-how-yall-doing-audio',\n",
       " '/reviews/26491-lisa-wells-believers-nonfiction',\n",
       " '/reviews/26534-erin-craig-small-favors-ya',\n",
       " '/reviews/26460-l-r-dorn-anatomy-desire-audio',\n",
       " '/reviews/26375-sunjeev-sahota-china-room-fiction',\n",
       " '/reviews/26426-chloe-shaw-what-dog-nonfiction',\n",
       " '/reviews/26373-anuk-arudpragasm-passage-north-fiction',\n",
       " '/reviews/26504-erica-waters-river-has-teeth-ya',\n",
       " '/reviews/26386-tahmima-anam-startup-wife-fiction',\n",
       " '/reviews/26412-john-lewis-carry-nonfiction']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracted URLs\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    p1=requests.get(\"https://bookpage.com/\"+url) #send get request to each url\n",
    "    soup=BeautifulSoup(p1.content)\n",
    "    \n",
    "    book_name.append(soup.find(\"h1\").text.replace(\"\\n\",'').replace('★ ','')) #Get book name\n",
    "    author_name.append(soup.find(\"h4\").text.replace(\"\\n\",'')) #Get author name\n",
    "    genre.append(soup.find(\"p\",class_=\"genre-links\").text.replace(\"\\n\",'')) # Get Genre\n",
    "    book_review.append(soup.find(\"div\",class_=\"article-body\").text.replace(\"\\n\",'')) #Get book review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#Checking the lengths for each list\n",
    "print(len(book_name))\n",
    "print(len(author_name))\n",
    "print(len(genre))\n",
    "print(len(book_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Book Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Y’all Doing?</td>\n",
       "      <td>Leslie Jordan</td>\n",
       "      <td>Audio / Nonfiction / Memoir</td>\n",
       "      <td>Emmy Award winner Leslie Jordan is making the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believers</td>\n",
       "      <td>Lisa Wells</td>\n",
       "      <td>Nonfiction / Environment / Nature</td>\n",
       "      <td>Poet, essayist and cultural commentator Lisa W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Small Favors</td>\n",
       "      <td>Erin A. Craig</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>In the small community of Amity Falls, 18-year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Anatomy of Desire</td>\n",
       "      <td>L.R. Dorn, Cast</td>\n",
       "      <td>Audio / Mystery &amp; Suspense / Suspense</td>\n",
       "      <td>We appear to be living in a golden age of crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China Room</td>\n",
       "      <td>Sunjeev Sahota</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Sunjeev Sahota’s brilliant second novel, the 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Book Name      Author Name  \\\n",
       "0       How Y’all Doing?    Leslie Jordan   \n",
       "1              Believers       Lisa Wells   \n",
       "2           Small Favors    Erin A. Craig   \n",
       "3  The Anatomy of Desire  L.R. Dorn, Cast   \n",
       "4             China Room   Sunjeev Sahota   \n",
       "\n",
       "                                   Genre  \\\n",
       "0            Audio / Nonfiction / Memoir   \n",
       "1      Nonfiction / Environment / Nature   \n",
       "2                        YA / YA Fiction   \n",
       "3  Audio / Mystery & Suspense / Suspense   \n",
       "4             Fiction / Literary Fiction   \n",
       "\n",
       "                                         Book Review  \n",
       "0  Emmy Award winner Leslie Jordan is making the ...  \n",
       "1  Poet, essayist and cultural commentator Lisa W...  \n",
       "2  In the small community of Amity Falls, 18-year...  \n",
       "3  We appear to be living in a golden age of crim...  \n",
       "4  Sunjeev Sahota’s brilliant second novel, the 2...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making dataframe for Book Review\n",
    "books=pd.DataFrame({})\n",
    "books[\"Book Name\"]=book_name[:5]\n",
    "books['Author Name']=author_name[:5]\n",
    "books[\"Genre\"]=genre[:5]\n",
    "books[\"Book Review\"]=book_review[:5]\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for the required data\n",
    "teams=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "ratings=[]\n",
    "mat_points=[]\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"): #Extract team names\n",
    "    teams.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"): #Extracting number of matches for first place team\n",
    "    matches.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"): #Extracting points for first place team\n",
    "    points.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"): #Extracting ratings for first place team\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): #Extracting matches and points for rest other teams\n",
    "    mat_points.append(i.text)\n",
    "    \n",
    "#Using for loop to store matches and points separately\n",
    "for i in range(0,len(mat_points)-1,2): \n",
    "    matches.append(mat_points[i]) #other teams number of matches\n",
    "    points.append(mat_points[i+1]) #other teams points\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"): #Extracting ratings for other teams\n",
    "    ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,471</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>22</td>\n",
       "      <td>2,267</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>29</td>\n",
       "      <td>2,639</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>27</td>\n",
       "      <td>2,071</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Matches Points  \\\n",
       "0   New Zealand      17  2,054   \n",
       "1       England      32  3,793   \n",
       "2     Australia      25  2,945   \n",
       "3         India      30  3,471   \n",
       "4  South Africa      22  2,267   \n",
       "5      Pakistan      27  2,524   \n",
       "6    Bangladesh      29  2,639   \n",
       "7   West Indies      27  2,222   \n",
       "8     Sri Lanka      27  2,071   \n",
       "9   Afghanistan      17  1,054   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              121               ...  \n",
       "1                                                119  \n",
       "2                                                118  \n",
       "3                                                116  \n",
       "4                                                103  \n",
       "5                                                 93  \n",
       "6                                                 91  \n",
       "7                                                 82  \n",
       "8                                                 77  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making dataframe for Top 10 ODI teams in Mens\n",
    "mens_odi=pd.DataFrame({})\n",
    "mens_odi[\"Team Name\"]=teams[:10]\n",
    "mens_odi[\"Matches\"]=matches[:10]\n",
    "mens_odi[\"Points\"]=points[:10]\n",
    "mens_odi[\"Ratings\"]=ratings[:10]\n",
    "mens_odi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for required data\n",
    "batsmen=[]\n",
    "teams=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"): #Batsmen at first place\n",
    "    batsmen.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"): #First place batsmen's team name\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"): #First place batsmen's ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): #Extract rest other batsmen's name\n",
    "    batsmen.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): #Other Batsmen's team name\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): #Other Batsmen's ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player                     Team Ratings\n",
       "0           Babar Azam  PAK                         873\n",
       "1          Virat Kohli                      IND     857\n",
       "2         Rohit Sharma                      IND     825\n",
       "3          Ross Taylor                       NZ     801\n",
       "4          Aaron Finch                      AUS     791\n",
       "5       Jonny Bairstow                      ENG     775\n",
       "6         David Warner                      AUS     773\n",
       "7            Shai Hope                       WI     773\n",
       "8  Francois du Plessis                       SA     770\n",
       "9      Kane Williamson                       NZ     754"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the dataframe for Top 10 ODI Batsmen in men\n",
    "top_batsmen=pd.DataFrame({})\n",
    "top_batsmen[\"Player\"]=batsmen[:10]\n",
    "top_batsmen[\"Team\"]=teams[:10]\n",
    "top_batsmen[\"Ratings\"]=ratings[:10]\n",
    "top_batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for required data\n",
    "bowlers=[]\n",
    "teams=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"): #First place bowler's name\n",
    "    bowlers.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"): #First place bowler's team name\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"): #First bowler's ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): #Scraping other bowler's name\n",
    "    bowlers.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):#Scraping teams name for rest other bowlers\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): #scraping ratings for rest other bowlers\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                    Team Ratings\n",
       "0        Trent Boult  NZ                         737\n",
       "1       Mehedi Hasan                     BAN     713\n",
       "2   Mujeeb Ur Rahman                     AFG     708\n",
       "3       Chris Woakes                     ENG     700\n",
       "4         Matt Henry                      NZ     691\n",
       "5     Jasprit Bumrah                     IND     690\n",
       "6     Josh Hazlewood                     AUS     660\n",
       "7      Kagiso Rabada                      SA     651\n",
       "8        Pat Cummins                     AUS     646\n",
       "9  Mustafizur Rahman                     BAN     645"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for Top 10 ODI bowlers in Men\n",
    "top_bowlers=pd.DataFrame({})\n",
    "top_bowlers[\"Player\"]=bowlers[:10]\n",
    "top_bowlers[\"Team\"]=teams[:10]\n",
    "top_bowlers[\"Ratings\"]=ratings[:10]\n",
    "top_bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for require data\n",
    "teams=[]\n",
    "matches=[]\n",
    "points=[]\n",
    "ratings=[]\n",
    "mat_points=[]\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"): #Extract team names\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"): #Extracting number of matches for first team\n",
    "    matches.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"): #Extracting number of points for first team\n",
    "    points.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"): #Extracting ratings for first team\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): #Extracting matches and points for rest other teams\n",
    "    mat_points.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "#Using for loop to separate matches and points\n",
    "for i in range(0,len(mat_points)-1,2):\n",
    "    matches.append(mat_points[i]) #Number of matches for rest other teams\n",
    "    points.append(mat_points[i+1]) #Points for rest other teams\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\")) #Extracting ratings for rest other teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>20</td>\n",
       "      <td>2,370</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>23</td>\n",
       "      <td>2,535</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>16</td>\n",
       "      <td>1,406</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>1,358</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name Matches Points  \\\n",
       "0     Australia      18  2,955   \n",
       "1       England      20  2,370   \n",
       "2  South Africa      24  2,828   \n",
       "3         India      23  2,535   \n",
       "4   New Zealand      21  1,947   \n",
       "5   West Indies      16  1,406   \n",
       "6      Pakistan      19  1,358   \n",
       "7    Bangladesh       5    306   \n",
       "8     Sri Lanka      11    519   \n",
       "9       Ireland       2     25   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              164               ...  \n",
       "1                                                119  \n",
       "2                                                118  \n",
       "3                                                110  \n",
       "4                                                 93  \n",
       "5                                                 88  \n",
       "6                                                 71  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame Top 10 ODI teams in women’s cricket\n",
    "womens_odi=pd.DataFrame({})\n",
    "womens_odi[\"Team Name\"]=teams[:10]\n",
    "womens_odi[\"Matches\"]=matches[:10]\n",
    "womens_odi[\"Points\"]=points[:10]\n",
    "womens_odi[\"Ratings\"]=ratings[:10]\n",
    "womens_odi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#See page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for the required data\n",
    "batsmen=[]\n",
    "teams=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"): #Scraping first player name\n",
    "    batsmen.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"): #Scraping first player's team name\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"): #Scraping firt player's ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): #Scraping other player's names\n",
    "    batsmen.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): #Scraping other player team names\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): #Scraping other player ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                    Team Ratings\n",
       "0    Stafanie Taylor  WI                         766\n",
       "1        Mithali Raj                     IND     762\n",
       "2        Lizelle Lee                      SA     758\n",
       "3       Alyssa Healy                     AUS     756\n",
       "4     Tammy Beaumont                     ENG     754\n",
       "5        Meg Lanning                     AUS     723\n",
       "6  Amy Satterthwaite                      NZ     715\n",
       "7     Natalie Sciver                     ENG     706\n",
       "8    Smriti Mandhana                     IND     701\n",
       "9    Laura Wolvaardt                      SA     683"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the dataframe for Top 10 women’s ODI players\n",
    "top_players=pd.DataFrame({})\n",
    "top_players[\"Player\"]=batsmen[:10]\n",
    "top_players[\"Team\"]=teams[:10]\n",
    "top_players[\"Ratings\"]=ratings[:10]\n",
    "top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#See page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for required data\n",
    "players=[]\n",
    "teams=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"): #Scraping first player name\n",
    "    players.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"): #Scraping first player's team name\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"): #Scraping first player's ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): #Scraping rest other players name\n",
    "    players.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): #Scraping rest other player team names\n",
    "    teams.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): #Scraping rest player ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Ratings\n",
       "0   Stafanie Taylor  WI                         435\n",
       "1    Marizanne Kapp                      SA     418\n",
       "2      Ellyse Perry                     AUS     418\n",
       "3    Natalie Sciver                     ENG     365\n",
       "4     Deepti Sharma                     IND     331\n",
       "5     Jess Jonassen                     AUS     307\n",
       "6  Ashleigh Gardner                     AUS     252\n",
       "7  Dane van Niekerk                      SA     243\n",
       "8     Sophie Devine                      NZ     242\n",
       "9   Katherine Brunt                     ENG     239"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for Top 10 women’s ODI all-rounder\n",
    "all_rounders=pd.DataFrame({})\n",
    "all_rounders[\"Player\"]=players[:10]\n",
    "all_rounders[\"Team\"]=teams[:10]\n",
    "all_rounders[\"Ratings\"]=ratings[:10]\n",
    "all_rounders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_2\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#See page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for the required data\n",
    "urls=[]\n",
    "product=[]\n",
    "price=[]\n",
    "image_url=[]\n",
    "avg_rating=[]\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"a-size-medium a-color-base a-text-normal\"): #Scraping the product name\n",
    "    product_name.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"a-price-whole\"): #Scraping price of the phone\n",
    "    price.append(i.text)\n",
    "for i in soup.find_all(\"span\",class_=\"a-icon-alt\"): #Scraping the average rating\n",
    "    avg_rating.append(i.text)\n",
    "    \n",
    "for i in soup.find_all(\"img\",class_=\"s-image\"): #Scraping Image URL\n",
    "    img_url.append(i.get(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "15\n",
      "20\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of each list\n",
    "print(len(product_name))\n",
    "print(len(price))\n",
    "print(len(avg_rating))\n",
    "print(len(img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I got Response 503, hence the entire data was not scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...</td>\n",
       "      <td>10,499</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...</td>\n",
       "      <td>12,490</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71GQUxuSpn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>11,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/710jkZNub3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71X5I1cVfb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716nHhG9SW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...</td>\n",
       "      <td>7,799</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71U2SiHgbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Redmi 9A(Midnight Black 3GB RAM 32GB Storage) ...</td>\n",
       "      <td>12,490</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Redmi 9A (Sea Blue 2GB RAM 32GB Storage) | 2GH...</td>\n",
       "      <td>5,498</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41QsvcpKaZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Redmi 9A (Midnight Black 2GB RAM 32GB Storage)...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71SSmaLA7x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name   Price  \\\n",
       "0   Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   6,999   \n",
       "1   Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...   8,999   \n",
       "2   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...  10,499   \n",
       "3   Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...  12,490   \n",
       "4   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...   9,999   \n",
       "5   Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...  11,499   \n",
       "6   Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...   8,999   \n",
       "7   Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...   9,999   \n",
       "8   Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...   7,799   \n",
       "9   Redmi 9A(Midnight Black 3GB RAM 32GB Storage) ...  12,490   \n",
       "10  Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...   6,999   \n",
       "11  Redmi 9A (Sea Blue 2GB RAM 32GB Storage) | 2GH...   5,498   \n",
       "12  Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...   6,999   \n",
       "13  Redmi 9A (Midnight Black 2GB RAM 32GB Storage)...  12,999   \n",
       "14  Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...  12,999   \n",
       "\n",
       "                Rating                                          Image URL  \n",
       "0   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "1   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71-Su4Wr0H...  \n",
       "2   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71A9Vo1Bat...  \n",
       "3   4.1 out of 5 stars  https://m.media-amazon.com/images/I/71GQUxuSpn...  \n",
       "4   4.2 out of 5 stars  https://m.media-amazon.com/images/I/61CnyJ-IbM...  \n",
       "5   4.1 out of 5 stars  https://m.media-amazon.com/images/I/710jkZNub3...  \n",
       "6   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71X5I1cVfb...  \n",
       "7   4.2 out of 5 stars  https://m.media-amazon.com/images/I/716nHhG9SW...  \n",
       "8   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71U2SiHgbi...  \n",
       "9   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "10  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71KCwNV6Mu...  \n",
       "11  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "12  3.1 out of 5 stars  https://m.media-amazon.com/images/I/41QsvcpKaZ...  \n",
       "13  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "14  4.1 out of 5 stars  https://m.media-amazon.com/images/I/71SSmaLA7x...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make dataframe mobile phones under Rs.20,000 on Amazon\n",
    "phones=pd.DataFrame({})\n",
    "phones[\"Product Name\"]=product_name[:15]\n",
    "phones[\"Price\"]=price[:15]\n",
    "phones[\"Rating\"]=avg_rating[:15]\n",
    "phones[\"Image URL\"]=img_url[:15]\n",
    "phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://forecast.weather.gov/MapClick.php?lat=37.77493000000004&lon=-122.41941999999995#.YPU3CegzbIU\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#See page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty Lists for required data\n",
    "period=[]\n",
    "short_desc=[]\n",
    "temp=[]\n",
    "description=[]\n",
    "\n",
    "#Period\n",
    "for i in soup.find_all(\"div\",class_=\"col-sm-2 forecast-label\"):\n",
    "    period.append(i.text) #Extracting Period\n",
    "    \n",
    "#Short Description and Temperature\n",
    "for i in soup.find_all(\"p\",class_=\"short-desc\"):\n",
    "    short_desc.append(i.get_text(separator=\" \").strip()) #Extracting short description using get_text separator as to eliminate line break\n",
    "    \n",
    "    temp.append(i.next_sibling.text) #Extracting temperature\n",
    "\n",
    "#Description\n",
    "for i in soup.find_all(\"div\",class_=\"col-sm-10 forecast-text\"):\n",
    "    description.append(i.text) #Extracting Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Mostly Sunny then Sunny and Breezy</td>\n",
       "      <td>High: 66 °F</td>\n",
       "      <td>Sunny, with a high near 66. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 55 °F</td>\n",
       "      <td>Partly cloudy, with a low around 55. West sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Mostly Sunny then Sunny and Breezy</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Sunny, with a high near 68. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday Night</td>\n",
       "      <td>Partly Cloudy and Breezy</td>\n",
       "      <td>Low: 54 °F</td>\n",
       "      <td>Partly cloudy, with a low around 54. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mostly Sunny then Sunny and Breezy</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65. Breezy, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday Night</td>\n",
       "      <td>Partly Cloudy and Breezy then Mostly Cloudy</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Partly cloudy, with a low around 53. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday Night</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Partly cloudy, with a low around 53.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Period                            Short Description  Temperature  \\\n",
       "0            Today           Mostly Sunny then Sunny and Breezy  High: 66 °F   \n",
       "1          Tonight                                Partly Cloudy   Low: 55 °F   \n",
       "2          Tuesday           Mostly Sunny then Sunny and Breezy  High: 68 °F   \n",
       "3    Tuesday Night                     Partly Cloudy and Breezy   Low: 54 °F   \n",
       "4        Wednesday           Mostly Sunny then Sunny and Breezy  High: 65 °F   \n",
       "5  Wednesday Night  Partly Cloudy and Breezy then Mostly Cloudy   Low: 53 °F   \n",
       "6         Thursday                                 Mostly Sunny  High: 65 °F   \n",
       "7   Thursday Night                                Partly Cloudy   Low: 53 °F   \n",
       "8           Friday                                 Mostly Sunny  High: 65 °F   \n",
       "\n",
       "                                         Description  \n",
       "0  Sunny, with a high near 66. Breezy, with a wes...  \n",
       "1  Partly cloudy, with a low around 55. West sout...  \n",
       "2  Sunny, with a high near 68. Breezy, with a wes...  \n",
       "3  Partly cloudy, with a low around 54. Breezy, w...  \n",
       "4  Mostly sunny, with a high near 65. Breezy, wit...  \n",
       "5      Partly cloudy, with a low around 53. Breezy.   \n",
       "6                 Mostly sunny, with a high near 65.  \n",
       "7               Partly cloudy, with a low around 53.  \n",
       "8                 Mostly sunny, with a high near 65.  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for Weather Forecast of San Francisco\n",
    "weather=pd.DataFrame({})\n",
    "weather[\"Period\"]=period[:9]\n",
    "weather[\"Short Description\"]=short_desc[:9]\n",
    "weather[\"Temperature\"]=temp[:9]\n",
    "weather[\"Description\"]=description[:9]\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://internshala.com/fresher-jobs/\"\n",
    "page=requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for the required data\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "for_ctc=[]\n",
    "ctc=[]\n",
    "date=[]\n",
    "\n",
    "#Job Titles\n",
    "for i in soup.find_all(\"div\",class_=\"heading_4_5 profile\"):\n",
    "    for j in i.find_all(\"a\"):\n",
    "        job_title.append(j.text) #Scraping job titles\n",
    "\n",
    "#Company Names\n",
    "for i in soup.find_all(\"div\",class_=\"heading_6 company_name\"):\n",
    "    for j in i.find_all(\"a\"):\n",
    "        company_name.append(j.text.replace(\"\\n\",\"\")) #Scraping Company Names\n",
    "    \n",
    "#CTC and Apple By dates\n",
    "for i in soup.find_all(\"div\",class_=\"item_body\"):\n",
    "    for_ctc.append(i.text.replace(\"\\t\",\"\").replace(\"\\n\",\"\")) #Scraping CTC and Apply By dates together\n",
    "    \n",
    "#Separating the CTC and Appy By dates to their respective lists\n",
    "for i in range(1,len(for_ctc),3): \n",
    "    ctc.append(for_ctc[i]) # CTC \n",
    "    date.append(for_ctc[i+1]) # Apply By dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply By</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer Success Executive</td>\n",
       "      <td>Printrove Products Pri...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Math Content Writer</td>\n",
       "      <td>Digituala Lab Enterpri...</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Research Coordinator</td>\n",
       "      <td>GastroLab India Privat...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>MiM-Essay             ...</td>\n",
       "      <td>4 - 5 LPA                                   ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Aptagrim Consulting LL...</td>\n",
       "      <td>3 - 4.5 LPA                                 ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Human Resources (HR) Manager</td>\n",
       "      <td>Best Roadways Limited ...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>16 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Triny.io              ...</td>\n",
       "      <td>3 - 6 LPA                                   ...</td>\n",
       "      <td>15 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Twurs</td>\n",
       "      <td>7.77 LPA                                    ...</td>\n",
       "      <td>15 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Search Engine Optimization (SEO) Specia...</td>\n",
       "      <td>Karthikk Vijay        ...</td>\n",
       "      <td>4 - 7 LPA                                   ...</td>\n",
       "      <td>15 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Customer Support Associate</td>\n",
       "      <td>SysCloud Technologies ...</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>15 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Junior Media &amp; Public Relations (PR) Executive</td>\n",
       "      <td>Vivaa Consulting      ...</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge               ...</td>\n",
       "      <td>3.75 LPA                                    ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human Resources (HR) Associate</td>\n",
       "      <td>Cloudify Technologies ...</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ionic App Developer</td>\n",
       "      <td>CloutNews             ...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Content Writer</td>\n",
       "      <td>Ukti</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Junior Graphic Designer</td>\n",
       "      <td>Muskurahat Foundation ...</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Marketing &amp; Communications Associate</td>\n",
       "      <td>Girl Power Talk       ...</td>\n",
       "      <td>3.4 - 4.8 LPA                               ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Jamocha Tech Private L...</td>\n",
       "      <td>5 LPA                                       ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Vegalmedia            ...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Node.js Developer</td>\n",
       "      <td>Infoware              ...</td>\n",
       "      <td>3 - 4.5 LPA                                 ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>Sleep Love            ...</td>\n",
       "      <td>3 - 3.5 LPA                                 ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Electronics Engineer</td>\n",
       "      <td>RXN Electric Private L...</td>\n",
       "      <td>5 - 7 LPA                                   ...</td>\n",
       "      <td>14 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Product Management Trainee</td>\n",
       "      <td>Agrometrics Analytics ...</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>General Management Trainee</td>\n",
       "      <td>Clopen Research       ...</td>\n",
       "      <td>3 - 4 LPA                                   ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Android App Developer</td>\n",
       "      <td>Medcords Healthcare So...</td>\n",
       "      <td>3.6 - 5 LPA                                 ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior/Junior Software Engineer</td>\n",
       "      <td>QuikieApps            ...</td>\n",
       "      <td>3 - 6 LPA                                   ...</td>\n",
       "      <td>13 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Shape.AI              ...</td>\n",
       "      <td>4 - 4.5 LPA                                 ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Shape.AI              ...</td>\n",
       "      <td>4 - 5 LPA                                   ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Trainee Engineer</td>\n",
       "      <td>Impressico Business So...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Full Stack Web Developer (MERN)</td>\n",
       "      <td>Shape.AI              ...</td>\n",
       "      <td>4 - 5 LPA                                   ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UI/UX Engineer</td>\n",
       "      <td>Digiledge             ...</td>\n",
       "      <td>4 - 6 LPA                                   ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Girl Power Talk       ...</td>\n",
       "      <td>3.4 - 4.8 LPA                               ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>UI/UX Designer</td>\n",
       "      <td>Girl Power Talk       ...</td>\n",
       "      <td>3.4 - 4.8 LPA                               ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Content Writer</td>\n",
       "      <td>Girl Power Talk       ...</td>\n",
       "      <td>3.4 - 4.8 LPA                               ...</td>\n",
       "      <td>12 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Clocr Inc.            ...</td>\n",
       "      <td>3 - 5 LPA                                   ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Digital Marketing Associate - Content</td>\n",
       "      <td>REALBRIDGE            ...</td>\n",
       "      <td>3 LPA                                       ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Junior Network Engineer</td>\n",
       "      <td>Wono Inc              ...</td>\n",
       "      <td>5.2 - 6 LPA                                 ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Junior Operations Associate</td>\n",
       "      <td>Wono Inc              ...</td>\n",
       "      <td>4.9 - 5.6 LPA                               ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Junior Design Engineer</td>\n",
       "      <td>Wono Inc              ...</td>\n",
       "      <td>5.4 - 6 LPA                                 ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Credit Analyst</td>\n",
       "      <td>Wono Inc              ...</td>\n",
       "      <td>5.2 - 5.9 LPA                               ...</td>\n",
       "      <td>11 Aug' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                          Customer Success Executive   \n",
       "1                        Advanced Math Content Writer   \n",
       "2                       Clinical Research Coordinator   \n",
       "3                                    Graphic Designer   \n",
       "4                                   Reactjs Developer   \n",
       "5                        Human Resources (HR) Manager   \n",
       "6                                  Software Developer   \n",
       "7                                Full Stack Developer   \n",
       "8   Junior Search Engine Optimization (SEO) Specia...   \n",
       "9                          Customer Support Associate   \n",
       "10     Junior Media & Public Relations (PR) Executive   \n",
       "11      Business Development Executive (Inside Sales)   \n",
       "12                     Human Resources (HR) Associate   \n",
       "13                                Ionic App Developer   \n",
       "14                                     Content Writer   \n",
       "15                            Junior Graphic Designer   \n",
       "16               Marketing & Communications Associate   \n",
       "17                               Full Stack Developer   \n",
       "18                     Business Development Executive   \n",
       "19                                  Node.js Developer   \n",
       "20                                   Fashion Designer   \n",
       "21                               Electronics Engineer   \n",
       "22                         Product Management Trainee   \n",
       "23                         General Management Trainee   \n",
       "24                              Android App Developer   \n",
       "25                    Senior/Junior Software Engineer   \n",
       "26                            Data Analytics Engineer   \n",
       "27                          Machine Learning Engineer   \n",
       "28                                   Trainee Engineer   \n",
       "29                    Full Stack Web Developer (MERN)   \n",
       "30                                     UI/UX Engineer   \n",
       "31                                      Web Developer   \n",
       "32                                     UI/UX Designer   \n",
       "33                                     Content Writer   \n",
       "34                       Digital Marketing Specialist   \n",
       "35              Digital Marketing Associate - Content   \n",
       "36                            Junior Network Engineer   \n",
       "37                        Junior Operations Associate   \n",
       "38                             Junior Design Engineer   \n",
       "39                                     Credit Analyst   \n",
       "\n",
       "                                              Company  \\\n",
       "0                           Printrove Products Pri...   \n",
       "1                           Digituala Lab Enterpri...   \n",
       "2                           GastroLab India Privat...   \n",
       "3                           MiM-Essay             ...   \n",
       "4                           Aptagrim Consulting LL...   \n",
       "5                           Best Roadways Limited ...   \n",
       "6                           Triny.io              ...   \n",
       "7                           Twurs                       \n",
       "8                           Karthikk Vijay        ...   \n",
       "9                           SysCloud Technologies ...   \n",
       "10                          Vivaa Consulting      ...   \n",
       "11                          GREedge               ...   \n",
       "12                          Cloudify Technologies ...   \n",
       "13                          CloutNews             ...   \n",
       "14                           Ukti                       \n",
       "15                          Muskurahat Foundation ...   \n",
       "16                          Girl Power Talk       ...   \n",
       "17                          Jamocha Tech Private L...   \n",
       "18                          Vegalmedia            ...   \n",
       "19                          Infoware              ...   \n",
       "20                          Sleep Love            ...   \n",
       "21                          RXN Electric Private L...   \n",
       "22                          Agrometrics Analytics ...   \n",
       "23                          Clopen Research       ...   \n",
       "24                          Medcords Healthcare So...   \n",
       "25                          QuikieApps            ...   \n",
       "26                          Shape.AI              ...   \n",
       "27                          Shape.AI              ...   \n",
       "28                          Impressico Business So...   \n",
       "29                          Shape.AI              ...   \n",
       "30                          Digiledge             ...   \n",
       "31                          Girl Power Talk       ...   \n",
       "32                          Girl Power Talk       ...   \n",
       "33                          Girl Power Talk       ...   \n",
       "34                          Clocr Inc.            ...   \n",
       "35                          REALBRIDGE            ...   \n",
       "36                          Wono Inc              ...   \n",
       "37                          Wono Inc              ...   \n",
       "38                          Wono Inc              ...   \n",
       "39                          Wono Inc              ...   \n",
       "\n",
       "                                                  CTC    Apply By  \n",
       "0     3 LPA                                       ...  16 Aug' 21  \n",
       "1     3 - 4 LPA                                   ...  16 Aug' 21  \n",
       "2     3 LPA                                       ...  16 Aug' 21  \n",
       "3     4 - 5 LPA                                   ...  16 Aug' 21  \n",
       "4     3 - 4.5 LPA                                 ...  16 Aug' 21  \n",
       "5     3 LPA                                       ...  16 Aug' 21  \n",
       "6     3 - 6 LPA                                   ...  15 Aug' 21  \n",
       "7     7.77 LPA                                    ...  15 Aug' 21  \n",
       "8     4 - 7 LPA                                   ...  15 Aug' 21  \n",
       "9     3 - 3.5 LPA                                 ...  15 Aug' 21  \n",
       "10    3 - 3.5 LPA                                 ...  14 Aug' 21  \n",
       "11    3.75 LPA                                    ...  14 Aug' 21  \n",
       "12    3 - 4 LPA                                   ...  14 Aug' 21  \n",
       "13    3 LPA                                       ...  14 Aug' 21  \n",
       "14    3 LPA                                       ...  14 Aug' 21  \n",
       "15    3 - 5 LPA                                   ...  14 Aug' 21  \n",
       "16    3.4 - 4.8 LPA                               ...  13 Aug' 21  \n",
       "17    5 LPA                                       ...  13 Aug' 21  \n",
       "18    3 LPA                                       ...  13 Aug' 21  \n",
       "19    3 - 4.5 LPA                                 ...  13 Aug' 21  \n",
       "20    3 - 3.5 LPA                                 ...  13 Aug' 21  \n",
       "21    5 - 7 LPA                                   ...  14 Aug' 21  \n",
       "22    3 - 4 LPA                                   ...  13 Aug' 21  \n",
       "23    3 - 4 LPA                                   ...  13 Aug' 21  \n",
       "24    3.6 - 5 LPA                                 ...  12 Aug' 21  \n",
       "25    3 - 6 LPA                                   ...  13 Aug' 21  \n",
       "26    4 - 4.5 LPA                                 ...  12 Aug' 21  \n",
       "27    4 - 5 LPA                                   ...  12 Aug' 21  \n",
       "28    3 LPA                                       ...  12 Aug' 21  \n",
       "29    4 - 5 LPA                                   ...  12 Aug' 21  \n",
       "30    4 - 6 LPA                                   ...  12 Aug' 21  \n",
       "31    3.4 - 4.8 LPA                               ...  12 Aug' 21  \n",
       "32    3.4 - 4.8 LPA                               ...  12 Aug' 21  \n",
       "33    3.4 - 4.8 LPA                               ...  12 Aug' 21  \n",
       "34    3 - 5 LPA                                   ...  11 Aug' 21  \n",
       "35    3 LPA                                       ...  11 Aug' 21  \n",
       "36    5.2 - 6 LPA                                 ...  11 Aug' 21  \n",
       "37    4.9 - 5.6 LPA                               ...  11 Aug' 21  \n",
       "38    5.4 - 6 LPA                                 ...  11 Aug' 21  \n",
       "39    5.2 - 5.9 LPA                               ...  11 Aug' 21  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making dataframe for Freshers Job Listings\n",
    "fresher_jobs=pd.DataFrame({})\n",
    "fresher_jobs[\"Job Title\"]=job_title\n",
    "fresher_jobs[\"Company\"]=company_name\n",
    "fresher_jobs[\"CTC\"]=ctc\n",
    "fresher_jobs[\"Apply By\"]=date\n",
    "fresher_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url=\"https://www.nobroker.in/property/sale/mumbai/Dadar?searchParam=W3sibGF0IjoxOS4wMTc3OTg5LCJsb24iOjcyLjg0NzgxMTk5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSkQ4MmdEdHZPNXpzUjBGdVpPVkJHaWtJIiwicGxhY2VOYW1lIjoiRGFkYXIifV0=&radius=2.0\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#See page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Empty lists for the required data\n",
    "h_title=[]\n",
    "loc=[]\n",
    "area=[]\n",
    "emi=[]\n",
    "price=[]\n",
    "emi_pri=[]\n",
    "\n",
    "#House Titles\n",
    "for i in soup.find_all(\"h2\",class_=\"heading-6 font-semi-bold nb__1AShY\"):\n",
    "    h_title.append(i.text) #Scraping House Titles\n",
    "\n",
    "#Locations\n",
    "for i in soup.find_all(\"div\",class_=\"nb__2CMjv\"):\n",
    "    loc.append(i.text) #Scraping Location of the House\n",
    "    \n",
    "#Area of House\n",
    "for i in soup.find_all(\"div\",class_=\"nb__3oNyC\"):\n",
    "    area.append(i.text) #Scraping House Area\n",
    "\n",
    "#EMI and Price together\n",
    "for i in soup.find_all(\"div\",class_=\"nb__2NPHR\"):\n",
    "    for j in i.find_all(\"div\"):\n",
    "        emi_pri.append(j.text) #Scraping House EMI and Price together\n",
    "\n",
    "#Separating EMI and Price and then appending them to their respective lists\n",
    "for i in range(3,len(emi_pri),7):\n",
    "    emi.append(emi_pri[i]) #EMI\n",
    "    price.append(emi_pri[i+2]) #Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#Checking the lengths for each list\n",
    "print(len(h_title))\n",
    "print(len(loc))\n",
    "print(len(area))\n",
    "print(len(emi))\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Sale  In Omkar Om Residency  C...</td>\n",
       "      <td>Near Bhoiwada Court Behind TATA Cancer Hospital</td>\n",
       "      <td>1,055 sqft</td>\n",
       "      <td>₹1.66 Lacs/Month</td>\n",
       "      <td>₹2.9 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 BHK Flat  For Sale  In Landmark Chs In Dadar...</td>\n",
       "      <td>opp wadala telephone exchange naigaon Dadar East</td>\n",
       "      <td>675 sqft</td>\n",
       "      <td>₹1.32 Lacs/Month</td>\n",
       "      <td>₹2.3 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Bombay Realty Ic...</td>\n",
       "      <td>Bombay Realty Icc  ram mandir dadar</td>\n",
       "      <td>2,151 sqft</td>\n",
       "      <td>₹4.81 Lacs/Month</td>\n",
       "      <td>₹8.4 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 RK Flat  For Sale  In Arjun Khot Wadi Vastu ...</td>\n",
       "      <td>JK sawant marg, near Plaza Cinema</td>\n",
       "      <td>350 sqft</td>\n",
       "      <td>₹63,045/Month</td>\n",
       "      <td>₹1.1 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Flat  For Sale  In Indrayani Complex  In...</td>\n",
       "      <td>N C. Kelkar Rd Near  Plaza Cinema</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>₹2.72 Lacs/Month</td>\n",
       "      <td>₹4.75 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1 BHK Flat  For Sale  In Mhada Society In Naig...</td>\n",
       "      <td>GD Ambekar Marg near Naigaon Police Quarters</td>\n",
       "      <td>310 sqft</td>\n",
       "      <td>₹28,657/Month</td>\n",
       "      <td>₹50 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 BHK Flat  For Sale  In Dadar West</td>\n",
       "      <td>Standalone Building, Ranade Road, Near INOX Na...</td>\n",
       "      <td>350 sqft</td>\n",
       "      <td>₹51,009/Month</td>\n",
       "      <td>₹89 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Flat  For Sale  In The Baya Park. In Dadar</td>\n",
       "      <td>New Samadhan Building, Tulsi Pipe Rd, Kasarava...</td>\n",
       "      <td>900 sqft</td>\n",
       "      <td>₹1.95 Lacs/Month</td>\n",
       "      <td>₹3.4 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 RK Flat  For Sale  In Mohan Naik Chs In Dada...</td>\n",
       "      <td>Street Number 14, Old bdd chawl, Naigaon, Dada...</td>\n",
       "      <td>350 sqft</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 BHK Flat  For Sale  In Matoshree Tower In Da...</td>\n",
       "      <td>Padmabai Thakkar Rd, Kasaravadi</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹2.58 Lacs/Month</td>\n",
       "      <td>₹4.5 Crores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  2 BHK Flat  For Sale  In Omkar Om Residency  C...   \n",
       "1  1 BHK Flat  For Sale  In Landmark Chs In Dadar...   \n",
       "2  3 BHK Apartment  For Sale  In Bombay Realty Ic...   \n",
       "3  1 RK Flat  For Sale  In Arjun Khot Wadi Vastu ...   \n",
       "4  3 BHK Flat  For Sale  In Indrayani Complex  In...   \n",
       "5  1 BHK Flat  For Sale  In Mhada Society In Naig...   \n",
       "6               1 BHK Flat  For Sale  In Dadar West    \n",
       "7  2 BHK Flat  For Sale  In The Baya Park. In Dadar    \n",
       "8  1 RK Flat  For Sale  In Mohan Naik Chs In Dada...   \n",
       "9  3 BHK Flat  For Sale  In Matoshree Tower In Da...   \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0   Near Bhoiwada Court Behind TATA Cancer Hospital   1,055 sqft   \n",
       "1   opp wadala telephone exchange naigaon Dadar East    675 sqft   \n",
       "2                Bombay Realty Icc  ram mandir dadar  2,151 sqft   \n",
       "3                  JK sawant marg, near Plaza Cinema    350 sqft   \n",
       "4                  N C. Kelkar Rd Near  Plaza Cinema  1,100 sqft   \n",
       "5       GD Ambekar Marg near Naigaon Police Quarters    310 sqft   \n",
       "6  Standalone Building, Ranade Road, Near INOX Na...    350 sqft   \n",
       "7  New Samadhan Building, Tulsi Pipe Rd, Kasarava...    900 sqft   \n",
       "8  Street Number 14, Old bdd chawl, Naigaon, Dada...    350 sqft   \n",
       "9                    Padmabai Thakkar Rd, Kasaravadi  1,200 sqft   \n",
       "\n",
       "                EMI         Price  \n",
       "0  ₹1.66 Lacs/Month   ₹2.9 Crores  \n",
       "1  ₹1.32 Lacs/Month   ₹2.3 Crores  \n",
       "2  ₹4.81 Lacs/Month   ₹8.4 Crores  \n",
       "3     ₹63,045/Month   ₹1.1 Crores  \n",
       "4  ₹2.72 Lacs/Month  ₹4.75 Crores  \n",
       "5     ₹28,657/Month      ₹50 Lacs  \n",
       "6     ₹51,009/Month      ₹89 Lacs  \n",
       "7  ₹1.95 Lacs/Month   ₹3.4 Crores  \n",
       "8     ₹40,120/Month      ₹70 Lacs  \n",
       "9  ₹2.58 Lacs/Month   ₹4.5 Crores  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for the House Details\n",
    "house=pd.DataFrame({})\n",
    "house[\"Title\"]=h_title\n",
    "house[\"Location\"]=loc\n",
    "house[\"Area\"]=area\n",
    "house[\"EMI\"]=emi\n",
    "house[\"Price\"]=price\n",
    "house"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
